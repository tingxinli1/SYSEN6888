{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import jieba\n",
    "from rouge_chinese import Rouge\n",
    "# from rouge import Rouge\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read preds, specify model name to get the test results\n",
    "model_name = 'chatglm2'\n",
    "# model_name = 'baichuan2'\n",
    "# model_name = 'bloomz'\n",
    "with open(f'./test_output_{model_name}.txt') as f:\n",
    "    preds = f.read()\n",
    "    preds = [line for line in preds.split('\\n') if len(line) > 0]\n",
    "# read labels\n",
    "labels = [line['summary'] for line in jsonlines.open('dev.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1070 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\asus\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.822 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "100%|██████████| 1070/1070 [00:09<00:00, 117.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': 30.556886074766354, 'rouge-2': 7.87192046728972, 'rouge-l': 25.391477663551402, 'bleu-2': 23.517177943925237, 'bleu-4': 9.11495429906542, 'meteor': 32.56504878504672}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# compute score\n",
    "score_dict = {\n",
    "    \"rouge-1\": [],\n",
    "    \"rouge-2\": [],\n",
    "    \"rouge-l\": [],\n",
    "    \"bleu-2\": [],\n",
    "    \"bleu-4\": [],\n",
    "    \"meteor\": []\n",
    "}\n",
    "\n",
    "for pred, label in tqdm(list(zip(preds, labels))):\n",
    "    # # 中文输出用jieba分词\n",
    "    hypothesis = list(jieba.cut(pred))\n",
    "    reference = list(jieba.cut(label))\n",
    "    # # 英文输出用nltk分词\n",
    "    # hypothesis = word_tokenize(pred)\n",
    "    # reference = word_tokenize(label)\n",
    "    rouge = Rouge()\n",
    "    hypothesis = ' '.join(hypothesis)\n",
    "    reference = ' '.join(reference)\n",
    "    if not hypothesis.strip() or not reference.strip():\n",
    "        continue\n",
    "    scores = rouge.get_scores(hypothesis , reference)\n",
    "    result = scores[0]\n",
    "\n",
    "    for k, v in result.items():\n",
    "        score_dict[k].append(round(v[\"f\"] * 100, 4))\n",
    "    bleu_score2 = sentence_bleu([list(label)], list(pred), weights=(0.5, 0.5), smoothing_function=SmoothingFunction().method3)\n",
    "    bleu_score4 = sentence_bleu([list(label)], list(pred), smoothing_function=SmoothingFunction().method3)\n",
    "    meteor = meteor_score([list(label)], list(pred))\n",
    "    score_dict[\"bleu-2\"].append(round(bleu_score2 * 100, 4))\n",
    "    score_dict[\"bleu-4\"].append(round(bleu_score4 * 100, 4))\n",
    "    score_dict[\"meteor\"].append(round(meteor * 100, 4))\n",
    "\n",
    "for k, v in score_dict.items():\n",
    "    score_dict[k] = float(np.mean(v))\n",
    "\n",
    "print(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_outputs_f = open('./results/all_outputs.txt', 'a')\n",
    "# all_outputs_f.truncate(0)\n",
    "# test_samples = [line for line in jsonlines.open('dev.json')]\n",
    "# preds = {}\n",
    "# model_names = ['bloomz', 'baichuan2', 'chatglm2']\n",
    "# for model_name in model_names:\n",
    "#     with open(f'./results/test_output_{model_name}.txt') as f:\n",
    "#         text = f.read()\n",
    "#         preds[model_name] = [line for line in text.split('\\n') if len(line) > 0]\n",
    "# for i in range(len(test_samples)):\n",
    "#     all_outputs_f.write(f\"输入：{test_samples[i]['content']}\\n\")\n",
    "#     for model_name in model_names:\n",
    "#         all_outputs_f.write(f\"{model_name}输出：{preds[model_name][i]}\\n\")\n",
    "#     all_outputs_f.write(f\"标注：{test_samples[i]['summary']}\\n\")\n",
    "#     all_outputs_f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
